# ğŸ›¡ï¸ Policy Copilot
**Real-time governance & safety layer for MCP-based AI agents**

Policy Copilot demonstrates how unsafe AI agents can be **controlled, audited,
and governed in real time** using a separate policy control plane.

This project is designed for hackathon judges, reviewers, and engineers
who want to understand **how agent safety actually works in practice**.

---

## ğŸš¨ The Problem

Modern AI agents are powerful â€” but dangerous by default.

An autonomous agent can:
- Read sensitive customer data (PII)
- Call external tools like email or APIs
- Use expensive or unapproved models
- Ignore prompt-based safety rules

**Prompt instructions are not enforcement.**
Once an agent is running, there is usually **no real control layer**.

---

## ğŸ’¡ The Idea

What if AI agents were governed like production systems?

Instead of trusting the agent:
- We **intercept its actions**
- We **enforce policies at runtime**
- We **separate execution from governance**

Thatâ€™s what **Policy Copilot** does.

---

## ğŸ§± What We Built

Policy Copilot is a **separate MCP server** that acts as a **policy control plane**
for other AI agents.

### Components

| Component | Purpose |
|---------|--------|
| **Worker Agent** | Unsafe-by-design AI agent |
| **Policy Copilot** | MCP server enforcing policies |
| **Policy Rules (YAML)** | Human-readable governance rules |
| **CLI Demo** | Shows enforcement clearly |
| **Archestra Config** | Conceptual orchestration layer |

---

## ğŸ§  High-Level Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI Demo â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” Policy Decisions
â”‚ Policy â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Copilot MCP â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ Allowed / Blocked â”‚
â–¼ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” Tool Calls â”‚
â”‚ Worker â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Agent MCP â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


**Key idea:**  
The agent does NOT decide what itâ€™s allowed to do.  
The **policy server does**.

---

## ğŸ¤– Worker Agent (Unsafe by Design)

The worker agent is intentionally designed to be unsafe so that
policy enforcement can be demonstrated clearly.

It can:
- Read customer data containing PII
- Attempt to send emails outside the system
- Request expensive or unapproved models

These actions would be unacceptable in production â€”  
**Policy Copilot exists to stop them at runtime.**

---

## ğŸ“œ Policy Rules (Human-Readable Governance)

All enforcement logic is defined in a human-readable YAML file:

`policy/rules.yaml`

```yaml
policies:
  - name: block_external_email
    type: tool_block
    tool: send_email
    reason: "External communication is not allowed"

  - name: redact_pii
    type: output_rewrite
    keywords:
      - "@example.com"

  - name: restrict_model
    type: model_limit
    allowed_models:
      - gpt-4o-mini

## ğŸ§  High-Level Architecture

